{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is based on an assignment from the DeepLearning.AI's Coursera course titled Convolutional Neural Networks. I have expanded on the assignment by adding functions to facilitate model evaluation and generalizing the architecture to include any number of layers with or without skip connections and with or without batch normalization.\n",
    "\n",
    "**Skills demonstrated:** multi-classification, tensorflow, ResNet architecture, model evaluation, general coding\n",
    "\n",
    "Overview: \n",
    "> ResNet architecture (He et al, 2015) famously revolutionized deep learning by elegantly addressing the issue of vanishing gradients in very deep networks by adding skip connections. This code builds a deep neural network using ResNet architecture. For the sake of comparison with pre-ResNet architectures, I include helper functions that easily allow the removal of skip connections. The model is trained on images of hands holding up 0-5 fingers and returns an integer corresponding to the gesture in each image.\n",
    "\n",
    "Models:\n",
    "> - Images are initially fed into an input layer, then through a ZeroPadding layer, a Conv2D layer, BatchNormalization, ReLU activation, then a MaxPool layer. From there, output is passed through a prescribed number of what I'll call ResNet blocks. Each ResNet block contains a convolutional block and a prescribed number of identity blocks.\n",
    ">- The convolutional blocks pass the input through three Conv2D layers with BatchNormalization and ReLU activation between, then pass the block input through a Conv2D and BatchNorm and adds it to the output of the third Conv2D layer before passing that sum through a ReLU activation. These blocks can change the dimension of the data.\n",
    ">- The identity blocks similarly pass the input through three Conv2D layers with BatchNormalization and ReLU activation between, but simply adds the output of the third Conv2D layer to the block input without transforming the input first. These blocks maintain data dimensions.\n",
    ">- After the last ResNet block, the output is passed through an AveragePooling2D layer, then a Flatten layer, then a Dense layer with softmax activation for prediction.\n",
    "\n",
    "Purpose: \n",
    "> Demonstrate the effectiveness of skip connections in addressing the issue of vanishing gradients in very deep neural networks.\n",
    "\n",
    "Datasets: \n",
    "\n",
    "> SIGNS dataset from DeepLearning.AI's Convolutional Neural Networks course. The dataset consists of 1080 training images and 120 test images of hands gesturing 0 through 5.\n",
    "    \n",
    "\n",
    "Target variable:\n",
    "\n",
    "> The number of digits held up in each image (0-5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "from matplotlib.pyplot import imshow\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from resnets_utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_b = resNet_builder([2, 3, 2], [3, 3, 3], [1, 2, 2], batch_norm = True, skip_connection=True,\n",
    "#                   first_filters = [64, 64, 256], input_shape = (64, 64, 3), classes = 6)\n",
    "model_b = resNet_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model_b.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00015)\n",
    "model_b.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig / 255.\n",
    "X_test = X_test_orig / 255.\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = np.squeeze(to_categorical(Y_train_orig, num_classes=6))\n",
    "Y_test = np.squeeze(to_categorical(Y_test_orig, num_classes=6))\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "34/34 [==============================] - 121s 3s/step - loss: 2.0333 - accuracy: 0.2972\n",
      "Epoch 2/5\n",
      "34/34 [==============================] - 110s 3s/step - loss: 1.4198 - accuracy: 0.5009\n",
      "Epoch 3/5\n",
      "34/34 [==============================] - 124s 4s/step - loss: 0.9339 - accuracy: 0.6759\n",
      "Epoch 4/5\n",
      "34/34 [==============================] - 113s 3s/step - loss: 0.7499 - accuracy: 0.7231\n",
      "Epoch 5/5\n",
      "34/34 [==============================] - 100s 3s/step - loss: 0.3676 - accuracy: 0.8602\n",
      "4/4 [==============================] - 3s 294ms/step - loss: 1.0554 - accuracy: 0.6583\n",
      "34/34 [==============================] - 11s 332ms/step - loss: 0.2431 - accuracy: 0.9083\n",
      "Time to train for 5 epochs: 568.04 seconds.\n",
      "Training Loss = 0.24306875467300415\n",
      "Training Accuracy = 0.9083333611488342\n",
      "Test Loss = 1.055376410484314\n",
      "Test Accuracy = 0.6583333611488342\n"
     ]
    }
   ],
   "source": [
    "model_t, stats = model_tester(model_b, X_train, Y_train, X_test, Y_test, num_epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_t.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 100\n",
    "imshow(X_test[ind])\n",
    "np.argmax(model_t.predict(tf.expand_dims(X_test[ind],axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"ResNet50_15epochs.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
